# 43.EFK

前面我们学习了 Kubernetes 集群中监控系统的搭建，除了对集群的监控报警之外，还有一项运维工作是非常重要的，那就是日志的收集。

应用程序和系统日志可以帮助我们了解集群内部的运行情况，日志对于我们调试问题和监视集群情况也是非常有用的。而且大部分的应用都会有日志记录，对于传统的应用大部分都会写入到本地的日志文件之中。对于容器化应用程序来说则更简单，只需要将日志信息写入到 stdout 和 stderr 即可，容器默认情况下就会把这些日志输出到宿主机上的一个 JSON 文件之中，同样我们也可以通过 `docker logs` 或者 `kubectl logs` 来查看到对应的日志信息。

但是，通常来说容器引擎或运行时提供的功能不足以记录完整的日志信息，比如，如果容器崩溃了、Pod 被驱逐了或者节点挂掉了，我们仍然也希望访问应用程序的日志。所以，日志应该独立于节点、Pod 或容器的生命周期，这种设计方式被称为 `cluster-level-logging`，即完全独立于 Kubernetes 系统，需要自己提供单独的日志后端存储、分析和查询工具。


## Kubernetes 中的基本日志

下面这个示例是 Kubernetes 中的一个基本日志记录的示例，直接将数据输出到标准输出流，如下：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
    - name: count
      image: busybox
      args:
        [
          /bin/sh,
          -c,
          'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done',
        ]
```

将上面文件保存为 counter-pod.yaml，该 Pod 每秒输出一些文本信息，创建这个 Pod：

```shell
$ kubectl apply -f counter-pod.yaml
pod "counter" created
```

创建完成后，可以使用 `kubectl logs` 命令查看日志信息：

```shell
$ kubectl logs counter
0: Thu Dec 27 15:47:04 UTC 2018
1: Thu Dec 27 15:47:05 UTC 2018
2: Thu Dec 27 15:47:06 UTC 2018
3: Thu Dec 27 15:47:07 UTC 2018
......
```


## Kubernetes 日志收集

Kubernetes 集群本身不提供日志收集的解决方案，一般来说有主要的 3 种方案来做日志收集：

- 在节点上运行一个 agent 来收集日志
- 在 Pod 中包含一个 sidecar 容器来收集应用日志
- 直接在应用程序中将日志信息推送到采集后端


### 节点日志采集代理

![1690634819752.png](./img/8A-0JCnD55QHvnmA/1693830249936-4bc4cc1b-805f-4374-b3d2-cc6f69f8c13b-557606.png)

通过在每个节点上运行一个日志收集的 agent 来采集日志数据，日志采集 agent 是一种专用工具，用于将日志数据推送到统一的后端。一般来说，这种 agent 用一个容器来运行，可以访问该节点上所有应用程序容器的日志文件所在目录。

由于这种 agent 必须在每个节点上运行，所以直接使用 DaemonSet 控制器运行该应用程序即可。在节点上运行一个日志收集的 agent 这种方式是最常见的一种方法，因为它只需要在每个节点上运行一个代理程序，并不需要对节点上运行的应用程序进行更改，对应用程序没有任何侵入性，但是这种方法也仅仅适用于收集输出到 stdout 和 stderr 的应用程序日志。


### 以 sidecar 容器收集日志

我们看上面的图可以看到有一个明显的问题就是我们采集的日志都是通过输出到容器的 stdout 和 stderr 里面的信息，这些信息会在本地的容器对应目录中保留成 JSON 日志文件，所以直接在节点上运行一个 agent 就可以采集到日志。但是如果我们的应用程序的日志是输出到容器中的某个日志文件的话呢？这种日志数据显然只通过上面的方案是采集不到的了。


#### 用 sidecar 容器重新输出日志

![1690634886362.png](./img/8A-0JCnD55QHvnmA/1693830251018-49337bdc-bb43-48d9-a9d4-c2a075f35aad-407106.png)

对于上面这种情况我们可以直接在 Pod 中启动另外一个 sidecar 容器，直接将应用程序的日志通过这个容器重新输出到 stdout，这样是不是通过上面的节点日志收集方案又可以完成了。

由于这个 sidecar 容器的主要逻辑就是将应用程序中的日志进行重定向打印，所以背后的逻辑非常简单，开销很小，而且由于输出到了 stdout 或者 stderr，所以我们也可以使用 kubectl logs 来查看日志了。

下面的示例是在 Pod 中将日志记录在了容器的两个本地文件之中：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
    - name: count
      image: busybox
      args:
        - /bin/sh
        - -c
        - >
          i=0;
          while true;
          do
            echo "$i: $(date)" >> /var/log/1.log;
            echo "$(date) INFO $i" >> /var/log/2.log;
            i=$((i+1));
            sleep 1;
          done
      volumeMounts:
        - name: varlog
          mountPath: /var/log
  volumes:
    - name: varlog
      emptyDir: {}
```

由于 Pod 中容器的特性，我们可以利用另外一个 sidecar 容器去获取到另外容器中的日志文件，然后将日志重定向到自己的 stdout 流中，可以将上面的 YAML 文件做如下修改：（two-files-counter-pod-streaming-sidecar.yaml）

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
    - name: count
      image: busybox
      args:
        - /bin/sh
        - -c
        - >
          i=0;
          while true;
          do
            echo "$i: $(date)" >> /var/log/1.log;
            echo "$(date) INFO $i" >> /var/log/2.log;
            i=$((i+1));
            sleep 1;
          done
      volumeMounts:
        - name: varlog
          mountPath: /var/log
    - name: count-log-1
      image: busybox
      args: [/bin/sh, -c, "tail -n+1 -f /var/log/1.log"]
      volumeMounts:
        - name: varlog
          mountPath: /var/log
    - name: count-log-2
      image: busybox
      args: [/bin/sh, -c, "tail -n+1 -f /var/log/2.log"]
      volumeMounts:
        - name: varlog
          mountPath: /var/log
  volumes:
    - name: varlog
      emptyDir: {}
```

直接创建上面的 Pod：

```shell
$ kubectl apply -f two-files-counter-pod-streaming-sidecar.yaml
pod "counter" created
```

运行成功后，我们可以通过下面的命令来查看日志的信息：

```shell
$ kubectl logs counter count-log-1
0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
$ kubectl logs counter count-log-2
Mon Jan  1 00:00:00 UTC 2001 INFO 0
Mon Jan  1 00:00:01 UTC 2001 INFO 1
Mon Jan  1 00:00:02 UTC 2001 INFO 2
...
```

这样前面节点上的日志采集 agent 就可以自动获取这些日志信息，而不需要其他配置。

这种方法虽然可以解决上面的问题，但是也有一个明显的缺陷，就是日志不仅会在原容器文件中保留下来，还会通过 stdout 输出后占用磁盘空间，这样无形中就增加了一倍磁盘空间。


#### 使用 sidecar 运行日志采集 agent

![1690634906491.png](./img/8A-0JCnD55QHvnmA/1693830469788-1d0a41c1-0f7f-4812-9bfa-583c02755a03-783481.png)

如果你觉得在节点上运行一个日志采集的代理不够灵活的话，那么你也可以创建一个单独的日志采集代理程序的 sidecar 容器，不过需要单独配置和应用程序一起运行。

不过这样虽然更加灵活，但是在 sidecar 容器中运行日志采集代理程序会导致大量资源消耗，因为你有多少个要采集的 Pod，就需要运行多少个采集代理程序，另外还无法使用 kubectl logs 命令来访问这些日志，因为它们不受 kubelet 控制。

举个例子，你可以使用的 Stackdriver，它使用 fluentd 作为记录剂。以下是两个可用于实现此方法的配置文件。第一个文件包含配置流利的 ConfigMap。

下面是 Kubernetes 官方的一个 fluentd 的配置文件示例，使用 ConfigMap 对象来保存：

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluentd.conf: |
    <source>
      type tail
      format none
      path /var/log/1.log
      pos_file /var/log/1.log.pos
      tag count.format1
    </source>

    <source>
      type tail
      format none
      path /var/log/2.log
      pos_file /var/log/2.log.pos
      tag count.format2
    </source>

    <match **>
      type google_cloud
    </match>
```

上面的配置文件是配置收集原文件 `/var/log/1.log` 和 `/var/log/2.log` 的日志数据，然后通过 google_cloud 这个插件将数据推送到 Stackdriver 后端去。

下面是我们使用上面的配置文件在应用程序中运行一个 fluentd 的容器来读取日志数据：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
    - name: count
      image: busybox
      args:
        - /bin/sh
        - -c
        - >
          i=0;
          while true;
          do
            echo "$i: $(date)" >> /var/log/1.log;
            echo "$(date) INFO $i" >> /var/log/2.log;
            i=$((i+1));
            sleep 1;
          done
      volumeMounts:
        - name: varlog
          mountPath: /var/log
    - name: count-agent
      image: k8s.gcr.io/fluentd-gcp:1.30
      env:
        - name: FLUENTD_ARGS
          value: -c /etc/fluentd-config/fluentd.conf
      volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: config-volume
          mountPath: /etc/fluentd-config
  volumes:
    - name: varlog
      emptyDir: {}
    - name: config-volume
      configMap:
        name: fluentd-config
```

上面的 Pod 创建完成后，容器 count-agent 就会将 count 容器中的日志进行收集然后上传。当然，这只是一个简单的示例，我们也完全可以使用其他的任何日志采集工具来替换 fluentd，比如 logstash、fluent-bit 等等。


### 直接从应用程序收集日志

![1690681169486.png](./img/8A-0JCnD55QHvnmA/1693830474201-dd7c2c59-adc4-43d9-b2ec-e4a804676465-100100.png)

除了上面的几种方案之外，我们也完全可以通过直接在应用程序中去显示的将日志推送到日志后端，但是这种方式需要代码层面的实现，也超出了 Kubernetes 本身的范围。下节课我们给大家演示下具体的日志收集的操作方法。

---


前面大家介绍了 Kubernetes 集群中的几种日志收集方案，Kubernetes 中比较流行的日志收集解决方案是 Elasticsearch、Fluentd 和 Kibana（EFK）技术栈，也是官方现在比较推荐的一种方案。

`Elasticsearch` 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。

Elasticsearch 通常与 `Kibana` 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。

`Fluentd` 是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。

我们先来配置启动一个可扩展的 Elasticsearch 集群，然后在 Kubernetes 集群中创建一个 Kibana 应用，最后通过 DaemonSet 来运行 Fluentd，以便它在每个 Kubernetes 工作节点上都可以运行一个 Pod。


## 安装 Elasticsearch 集群

在创建 Elasticsearch 集群之前，我们先创建一个命名空间，我们将在其中安装所有日志相关的资源对象。

```shell
$ kubectl create ns kube-log
```

由于 Elasticsearch 集群复杂度还是比较高的，前面几期课程我们都是使用的手动方式来部署的，但是后续的运维和维护起来成本较高，对于这种复杂度较高的有状态应用，一般都会去开发对应的 Operator 来进行部署，这样可以简化部署过程，也可以方便后续的升级、扩容等操作，比如前面我们介绍的 Prometheus Operator、VictoriaMetrics Operator 等等。

同样的，对于 Elasticsearch 应用，官方也有基于 Kubernetes Operator 的应用：[Elastic Cloud on Kubernetes (ECK)](https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-quickstart.html)，用户可使用该产品在 Kubernetes 上配置、管理和运行 Elasticsearch 集群。


### 安装 ES 集群

ECK 是一个 Elasticsearch Operator，但远不止于此。ECK 使用 Kubernetes Operator 模式构建而成，需要安装在 Kubernetes 集群内，其功能绝不仅限于简化 Kubernetes 上 Elasticsearch 和 Kibana 的部署工作这一项任务。ECK 专注于简化所有后期运行工作，例如：

- 管理和监测多个集群
- 轻松升级至新的版本
- 扩大或缩小集群容量
- 更改集群配置
- 动态调整本地存储的规模
- 备份等等

ECK 不仅能自动完成所有运行和集群管理任务，还专注于简化在 Kubernetes 上使用 Elasticsearch 的完整体验。ECK 的愿景是为 Kubernetes 上的 Elastic 产品和解决方案提供 SaaS 般的体验。在 ECK 上启动的所有 Elasticsearch 集群都默认受到保护，这意味着在最初创建的那一刻便已启用加密并受到默认强密码的保护。

通过 ECK 部署的所有集群都包括强大的基础（免费）级功能，例如可实现密集存储的冻结索引、Kibana Spaces、Canvas、Elastic Maps，等等，甚至可以使用 Elastic Logs 和 Elastic Infrastructure 应用监测 Kubernetes 日志和基础设施。我们可以获得在 Kubernetes 上使用 Elastic Stack 完整功能的体验。

ECK 内构建了 Elastic Local Volume，这是一个适用于 Kubernetes 的集成式存储驱动器。ECK 中还融入了很多最佳实践，例如在缩小规模之前对节点进行 drain 操作，在扩大规模的时候对分片进行再平衡，等等。确保在配置变动过程中不会丢失数据，到确保在规模调整过程中实现零中断。

接下来我们就来安装下 ECK，需要注意的是目前的 ECK 版本支持的 Kubernetes 集群版本为 1.24-1.27。首先需要安装 CRD：

```shell
$ kubectl create -f https://download.elastic.co/downloads/eck/2.9.0/crds.yaml
customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created
```

这会将 ECK 支持的 CRD 安装到 Kubernetes 集群中，接下来我们就可以安装 ECK Operator 了：

```shell
$ kubectl apply -f https://download.elastic.co/downloads/eck/2.9.0/operator.yaml
namespace/elastic-system created
serviceaccount/elastic-operator created
secret/elastic-webhook-server-cert created
configmap/elastic-operator created
clusterrole.rbac.authorization.k8s.io/elastic-operator created
clusterrole.rbac.authorization.k8s.io/elastic-operator-view created
clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created
clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created
service/elastic-webhook-server created
statefulset.apps/elastic-operator created
validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created
```

ECK Operator 默认会被安装在 `elastic-system` 命名空间中，同样还会创建一系列 RBAC 规则，这些规则用于控制 ECK Operator 对集群的管理权限，最终的 Operator 会以 StatefulSet 的方式运行在 Kubernetes 集群中。

```shell
$ kubectl get sts -n elastic-system
NAME               READY   AGE
elastic-operator   1/1     7m13s
$ kubectl get pods -n elastic-system
NAME                 READY   STATUS    RESTARTS   AGE
elastic-operator-0   1/1     Running   0          31m
```

ECK Operator 启动成功后，我们就可以开始创建 Elasticsearch 集群了。但是需要注意的是如果你的 Kubernetes 集群没有任何具有至少 2GiB 可用内存的节点，则 pod 将陷入 Pending 状态，这是因为 Elasticsearch 集群需要至少 2GiB 内存才能正常运行。

要创建 Elasticsearch 集群，现在我们只需要创建一个 `Elasticsearch` 资源对象就可以了，这个资源对象定义了 Elasticsearch 集群的配置，比如版本、节点数量、存储大小、内存大小等等，如下所示：

```yaml
# es.yaml
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: demo
  namespace: kube-log
spec:
  version: 8.9.0
  image: elastic/elasticsearch:8.9.0 # 默认为 docker.elastic.co/elasticsearch/elasticsearch:8.9.0
  http:
    tls:
      selfSignedCertificate:
        disabled: true # 为了方便测试，这里禁用了 TLS
    service:
      spec:
        type: NodePort # 为了方便测试，这里使用 NodePort
  nodeSets:
    - name: default
      count: 1
      config:
        node.store.allow_mmap: false
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data # 除非为数据路径设置了卷挂载，否则请勿更改此名称。
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 5Gi
            storageClassName: cfsauto # 配置一个可用的 StorageClass
```

上面的配置文件中我们定义了一个 Elasticsearch 集群，集群名称为 `demo`，版本为 `8.9.0`，节点数量为 `1`，并且禁用了 `mmap`。默认情况下，Operator 会为 Elasticsearch 集群中的每个 Pod 创建一个容量为 1Gi 的 PVC，所以需要你集群中有默认的 StorageClass 才可以生效。当然我们也可以定义自己的卷声明模板，其中包含所需的存储容量和（可选）与持久卷关联的 Kubernetes 存储类。

直接应用上面的配置文件即可：

```shell
$ kubectl apply -f es.yaml
elasticsearch.elasticsearch.k8s.elastic.co/demo created
$ kubectl get elasticsearch -n kube-log
NAME   HEALTH   NODES   VERSION   PHASE   AGE
demo   green    1       8.9.0     Ready   10m
```

创建后，ECK Operator 会自动创建和管理 Kubernetes 资源，以实现 Elasticsearch 集群的理想状态。

```shell
$ kubectl get pods -n kube-log
NAME                READY   STATUS    RESTARTS   AGE
demo-es-default-0   1/1     Running   0          33s
$ kubectl get svc -n kube-log
NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
demo-es-default         ClusterIP   None            <none>        9200/TCP         2m10s
demo-es-http            NodePort    10.108.56.15    <none>        9200:30547/TCP   2m10s
demo-es-internal-http   ClusterIP   10.100.130.71   <none>        9200/TCP         2m10s
demo-es-transport       ClusterIP   None            <none>        9300/TCP         2m10s
```

系统会自动创建一个名为 `elastic` 的默认用户，其密码存储在 Kubernetes Secret 中：

```shell
$ PASSWORD=$(kubectl get secret demo-es-elastic-user -n kube-log -o go-template='{{.data.elastic | base64decode}}')
```

然后我们可以通过 `curl` 命令来测试集群是否正常：

```shell
$ curl -u "elastic:$PASSWORD" "http://<nodeip>:30547"
{
  "name" : "demo-es-default-0",
  "cluster_name" : "demo",
  "cluster_uuid" : "-RrzPgZNToaYh4NVgsoM2Q",
  "version" : {
    "number" : "8.9.0",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "8aa461beb06aa0417a231c345a1b8c38fb498a0d",
    "build_date" : "2023-07-19T14:43:58.555259655Z",
    "build_snapshot" : false,
    "lucene_version" : "9.7.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}
```

如果看到上面的信息输出证明这个 Elasticsearch 集群已经正常运行了。

当然我们还可以添加和修改原始集群规范，当然我们需要确保 Kubernetes 集群有足够的资源来适应更改（额外的存储空间、足够的内存和 CPU 资源来临时启动新的 pod 等），比如我们可以将 count 修改为 2，然后重新应用资源对象即可。

```shell
$ kubectl get elasticsearch -n kube-log
NAME   HEALTH   NODES   VERSION   PHASE   AGE
demo   green    2       8.9.0     Ready   33m
```

同样如果想将 Elasticsearch 按角色分组，可以使用 `nodeSets` 来定义，比如我们可以定义一个 `master` 节点组，然后将 `nodeSets` 的 `config.node.roles` 设置为 `master` 即可，如下所示：

```yaml
nodeSets:
  - name: master
    count: 1
    config:
      node.roles: ["master"]
      node.store.allow_mmap: false
  - name: data
    count: 1
    config:
      node.roles: ["data"]
      node.store.allow_mmap: false
  - name: ingest
    count: 1
    config:
      node.roles: ["ingest"]
      node.store.allow_mmap: false
```


### 安装 Kibana

Elasticsearch 集群安装完成后接下来配置安装 Kibana，同样的我们只需要创建一个 `Kibana` 的 CRD 资源对象即可，如下所示：

```yaml
# kibana.yaml
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: demo
  namespace: kube-log
spec:
  version: 8.9.0
  count: 1
  http:
    tls:
      selfSignedCertificate:
        disabled: true
    service:
      spec:
        type: NodePort # 为了方便测试，这里使用 NodePort
  elasticsearchRef:
    name: demo
  podTemplate:
    spec:
      containers:
        - name: kibana
          resources: # 默认的自由为100m、50Mi，这里我们修改为500m、512Mi
            requests:
              memory: 512Mi
              cpu: 500m
            limits:
              memory: 512Mi
              cpu: 500m
```

在上面的配置文件中我们定义了一个 Kibana 资源对象，名称为 `demo`，版本为 `8.9.0`，节点数量为 `1`，并且关联了上面创建的 Elasticsearch 集群，同样为了方便测试我们也禁用了 TLS，并将 Kibana 以 NodePort 的方式暴露出来。

同样直接应用上面的配置文件即可：

```shell
$ kubectl apply -f kibana.yaml
$ kubectl get kibana -n kube-log
NAME   HEALTH   NODES   VERSION   AGE
demo   green    1       8.9.0     8m9s
```

创建后，ECK Operator 会自动创建和管理 Kubernetes 资源，以实现 Kibana 集群的理想状态，这里会创建一个 Kibana Deployment 和一个 Kibana Service，如下所示：

```shell
$ kubectl get deployment -n kube-log
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
demo-kb   1/1     1            0           5m30s
$ kubectl get svc demo-kb-http -n kube-log
NAME           TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
demo-kb-http   NodePort   10.105.229.233   <none>        5601:32023/TCP   106s
```

当 Kibana 的 Pod 成功运行后，就可以从任意节点 `http://IP:32023` 来访问 Kibana 了。

![1690885913802.jpg](./img/8A-0JCnD55QHvnmA/1693830485642-e34aa395-4020-4273-89a8-8d5d15afaa3c-394388.jpeg)

我们可以看到会跳转到登录页面，让我们输出用户名、密码，这里我们输入上面配置的用户名 `elastic`，密码为上面获取的 `PASSWORD` 的值。登录成功后进入如下所示的 Kibana 主页：

![1690886160083.jpg](./img/8A-0JCnD55QHvnmA/1693830586678-bc0c0041-cefc-45b9-ace4-5605fdf1323f-420325.jpeg)


## 部署 Fluentd

`Fluentd` 是一个高效的日志聚合器，是用 Ruby 编写的，并且可以很好地扩展。对于大部分企业来说，Fluentd 足够高效并且消耗的资源相对较少，另外一个工具 `Fluent-bit` 更轻量级，占用资源更少，但是插件相对 Fluentd 来说不够丰富，所以整体来说，Fluentd 更加成熟，使用更加广泛，所以这里我们使用 Fluentd 来作为日志收集工具。


### 工作原理

Fluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过 300 个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：

- 首先 Fluentd 从多个日志源获取数据
- 结构化并且标记这些数据
- 然后根据匹配的标签将数据发送到多个目标服务去

![7moPNc.jpg](./img/8A-0JCnD55QHvnmA/1693830586954-8dd847df-9a89-4508-b844-598e80049fdb-908103.jpeg)


### 配置

一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。


#### 日志源配置

比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：

```nginx
<source>
  @id fluentd-containers.log
  @type tail                             # Fluentd 内置的输入方式，其原理是不停地从源文件中获取新的日志。
  path /var/log/containers/*.log         # 挂载的宿主机容器日志地址
  pos_file /var/log/es-containers.log.pos
  tag raw.kubernetes.*                   # 设置日志标签
  read_from_head true
  <parse>                                # 多行格式化成JSON
    @type multi_format                   # 使用 multi-format-parser 解析器插件
    <pattern>
      format json                        # JSON 解析器
      time_key time                      # 指定事件时间的时间字段
      time_format %Y-%m-%dT%H:%M:%S.%NZ  # 时间格式
    </pattern>
    <pattern>
      format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    </pattern>
  </parse>
</source>
```

上面配置部分参数说明如下：

- id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据
- type：Fluentd 内置的指令，`tail` 表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是 `http` 表示通过一个 GET 请求来收集数据。
- path：`tail` 类型下的特定参数，告诉 Fluentd 采集 `/var/log/containers` 目录下的所有日志，这是 docker 在 Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。
- pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。
- tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。


#### 路由配置

上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：

```nginx
<match **>
  @id elasticsearch
  @type elasticsearch
  @log_level info
  include_tag_key true
  type_name fluentd
  host "#{ENV['OUTPUT_HOST']}"
  port "#{ENV['OUTPUT_PORT']}"
  logstash_format true
  <buffer>
    @type file
    path /var/log/fluentd-buffers/kubernetes.system.buffer
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 5s
    retry_forever
    retry_max_interval 30
    chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
    queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
    overflow_action block
  </buffer>
</match>
```

- `match`：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成 `**`。
- `id`：目标的一个唯一标识符。
- `type`：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。
- `log_level`：指定要捕获的日志级别，我们这里配置成 `info`，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elasticsearch。
- `host/port`：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。
- `logstash_format`：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为 `true`，Fluentd 将会以 logstash 格式来转发结构化的日志数据。
- `buffer`： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。


#### 过滤

由于 Kubernetes 集群中应用太多，也还有很多历史数据，所以我们可以只将某些应用的日志进行收集，比如我们只采集具有 `logging=true` 这个 Label 标签的 Pod 日志，这个时候就需要使用 filter，如下所示：

```yaml
# 删除无用的属性
<filter kubernetes.**>
  @type record_transformer
  remove_keys $.docker.container_id,$.kubernetes.container_image_id,$.kubernetes.pod_id,$.kubernetes.namespace_id,$.kubernetes.master_url,$.kubernetes.labels.pod-template-hash
</filter>
# 只保留具有logging=true标签的Pod日志
<filter kubernetes.**>
  @id filter_log
  @type grep
  <regexp>
    key $.kubernetes.labels.logging
    pattern ^true$
  </regexp>
</filter>
```


### 安装

要收集 Kubernetes 集群的日志，直接用 DaemonSet 控制器来部署 Fluentd 应用，这样，它就可以从 Kubernetes 节点上采集日志，确保在集群中的每个节点上始终运行一个 Fluentd 容器。当然可以直接使用 Helm 来进行一键安装，为了能够了解更多实现细节，我们这里还是采用手动方法来进行安装。

> 可以直接使用官方的对于 Kubernetes 集群的安装文档: [https://docs.fluentd.org/container-deployment/kubernetes](https://docs.fluentd.org/container-deployment/kubernetes)。


首先，我们通过 ConfigMap 对象来指定 Fluentd 配置文件，新建 `fluentd-config.yaml` 文件，文件内容如下：

```yaml
# fluentd-config.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-conf
  namespace: kube-log
data:
  # 容器日志
  containers.input.conf: |-
    <source>
      @id fluentd-containers.log
      @type tail                              # Fluentd 内置的输入方式，其原理是不停地从源文件中获取新的日志
      path /var/log/containers/*.log          # 容器日志路径
      pos_file /var/log/es-containers.log.pos  # 记录读取的位置
      tag raw.kubernetes.*                    # 设置日志标签
      read_from_head true                     # 从头读取
      <parse>                                 # 多行格式化成JSON
        # 可以使用我们介绍过的 multiline 插件实现多行日志
        @type multi_format                    # 使用 multi-format-parser 解析器插件
        <pattern>
          format json                         # JSON解析器
          time_key time                       # 指定事件时间的时间字段
          time_format %Y-%m-%dT%H:%M:%S.%NZ   # 时间格式
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

    # 在日志输出中检测异常(多行日志)，并将其作为一条日志转发
    # https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions
    <match raw.kubernetes.**>           # 匹配 tag 为 raw.kubernetes.** 日志信息
      @id raw.kubernetes
      @type detect_exceptions           # 使用 detect-exceptions 插件处理异常栈信息
      remove_tag_prefix raw             # 移除 raw 前缀
      message log
      multiline_flush_interval 5
    </match>

    <filter **>  # 拼接日志
      @id filter_concat
      @type concat                # Fluentd Filter 插件，用于连接多个日志中分隔的多行日志
      key message
      multiline_end_regexp /\n$/  # 以换行符 \n 拼接
      separator ""
    </filter>

    # 添加 Kubernetes metadata 数据
    <filter kubernetes.**>
      @id filter_kubernetes_metadata
      @type kubernetes_metadata
    </filter>

    # 修复 ES 中的 JSON 字段
    # 插件地址：https://github.com/repeatedly/fluent-plugin-multi-format-parser
    <filter kubernetes.**>
      @id filter_parser
      @type parser                # multi-format-parser 多格式解析器插件
      key_name log                # 在要解析的日志中指定字段名称
      reserve_data true           # 在解析结果中保留原始键值对
      remove_key_name_field true  # key_name 解析成功后删除字段
      <parse>
        @type multi_format
        <pattern>
          format json
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # 删除一些多余的属性
    <filter kubernetes.**>
      @type record_transformer
      remove_keys $.docker.container_id,$.kubernetes.container_image_id,$.kubernetes.pod_id,$.kubernetes.namespace_id,$.kubernetes.master_url,$.kubernetes.labels.pod-template-hash
    </filter>

    # 只保留具有logging=true标签的Pod日志
    <filter kubernetes.**>
      @id filter_log
      @type grep
      <regexp>
        key $.kubernetes.labels.logging
        pattern ^true$
      </regexp>
    </filter>

  ###### 监听配置，一般用于日志聚合用 ######
  forward.input.conf: |-
    # 监听通过TCP发送的消息
    <source>
      @id forward
      @type forward
    </source>

  output.conf: |-
    <match **>
      @id elasticsearch
      @type elasticsearch
      @log_level info
      include_tag_key true
      host demo-es-internal-http  # Elasticsearch 服务地址
      port 9200
      user elastic # FLUENT_ELASTICSEARCH_USER 
      password $PASSWORD  # FLUENT_ELASTICSEARCH_PASSWORD
      logstash_format true
      logstash_prefix k8s
      request_timeout 30s
      <buffer>
        @type file  # 缓存类型
        path /var/log/fluentd-buffers/kubernetes.system.buffer  # 缓存路径
        flush_mode interval  
        retry_type exponential_backoff  # 重试类型
        flush_thread_count 2  # 刷新线程数
        flush_interval 5s  # 刷新间隔
        retry_forever # 重试次数
        retry_max_interval 30 # 最大重试间隔
        chunk_limit_size 2M # 缓存大小
        queue_limit_length 8  # 队列长度
        overflow_action block  # 溢出处理方式
      </buffer>
    </match>
```

上面配置文件中我们只配置了 docker 容器日志目录，收集到数据经过处理后发送到 `elasticsearch-client:9200` 服务。

然后新建一个 `fluentd-ds.yaml` 的文件，文件内容如下：

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd-es
  namespace: kube-log
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-es
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
rules:
  - apiGroups:
      - ""
    resources:
      - "namespaces"
      - "pods"
    verbs:
      - "get"
      - "watch"
      - "list"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-es
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: fluentd-es
    namespace: kube-log
    apiGroup: ""
roleRef:
  kind: ClusterRole
  name: fluentd-es
  apiGroup: ""
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-log
  labels:
    app: fluentd
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
        kubernetes.io/cluster-service: "true"
    spec:
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          effect: NoSchedule
      serviceAccountName: fluentd-es
      containers:
        - name: fluentd
          image: quay.io/fluentd_elasticsearch/fluentd:v4.4.3
          volumeMounts:
            - name: fluentconfig
              mountPath: /etc/fluent/config.d
            - name: varlog
              mountPath: /var/log
      volumes:
        - name: fluentconfig
          configMap:
            name: fluentd-conf
        - name: varlog
          hostPath:
            path: /var/log
```

我们将上面创建的 `fluentd-config` 这个 ConfigMap 对象通过 volumes 挂载到了 Fluentd 容器中，另外为了能够灵活控制哪些节点的日志可以被收集，还可以添加了一个 `nodSelector` 属性：

```yaml
nodeSelector:
  kubernetes.io/fluentd-ds-ready: "true"
```

意思就是要想采集节点的日志，那么我们就需要给节点打上上面的标签。

> 如果你需要在其他节点上采集日志，则需要给对应节点打上标签，使用如下命令：`kubectl label nodes node名 kubernetes.io/fluentd-ds-ready=true`。


另外由于我们的集群使用的是 kubeadm 搭建的，默认情况下 master 节点有污点，所以如果要想也收集 master 节点的日志，则需要添加上容忍：

```yaml
tolerations:
  - operator: Exists
```

分别创建上面的 ConfigMap 对象和 DaemonSet：

```shell
$ kubectl create -f fluentd-config.yaml
configmap "fluentd-conf" created
$ kubectl create -f fluentd-ds.yaml
serviceaccount "fluentd-es" created
clusterrole.rbac.authorization.k8s.io "fluentd-es" created
clusterrolebinding.rbac.authorization.k8s.io "fluentd-es" created
daemonset.apps "fluentd" created
```

创建完成后，查看对应的 Pods 列表，检查是否部署成功：

```shell
$ kubectl get pods -n kube-log
NAME                       READY   STATUS    RESTARTS   AGE
demo-es-default-0          1/1     Running   0          44h
demo-kb-7bcf498c4b-tf5t4   1/1     Running   0          43h
fluentd-2jnvq              1/1     Running   0          71s
fluentd-rbr55              1/1     Running   0          71s
fluentd-zz86c              1/1     Running   0          71s
```

Fluentd 启动成功后，这个时候就可以发送日志到 ES 了，但是我们这里是过滤了只采集具有 `logging=true` 标签的 Pod 日志，所以现在还没有任何数据会被采集。

下面我们部署一个简单的测试应用， 新建 `counter.yaml` 文件，文件内容如下：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
  labels:
    logging: "true" # 一定要具有该标签才会被采集
spec:
  containers:
    - name: count
      image: busybox
      args:
        [
          /bin/sh,
          -c,
          'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done',
        ]
```

该 Pod 只是简单将日志信息打印到 `stdout`，所以正常来说 Fluentd 会收集到这个日志数据，在 Kibana 中也就可以找到对应的日志数据了，使用 kubectl 工具创建该 Pod：

```shell
$ kubectl create -f counter.yaml
$ kubectl get pods
NAME                             READY   STATUS    RESTARTS   AGE
counter                          1/1     Running   0          9h
```

Pod 创建并运行后，回到 Kibana Dashboard 页面，点击左侧最下面的 `Management` -> `Stack Management`，进入管理页面，点击左侧 `Data` 下面的 `Index Management`，正常就可以看到一个前缀为 `k8s` 的索引，如下所示：

![1691051618206.jpg](./img/8A-0JCnD55QHvnmA/1693830586829-48963354-443d-4fb8-8976-bd016704285e-068990.jpeg)

然后切换到 `Kibana` 下面的 `Data Views`，我们需要创建 Data View 才能使用该索引数据，点击 `Create data view` 开始创建数据视图，如下所示：

![1691051795505.jpg](./img/8A-0JCnD55QHvnmA/1693830586851-922f2c1c-cdcd-41a0-8353-821f64664d2b-417578.jpeg)

在这里可以配置我们需要的 Elasticsearch 索引，前面 Fluentd 配置文件中我们采集的日志使用的是 logstash 格式，定义了一个 `k8s` 的前缀，所以这里只需要在文本框中输入 `k8s-*` 即可匹配到 Elasticsearch 集群中采集的 Kubernetes 集群日志数据。然后配置使用哪个字段按时间过滤日志数据，在下拉列表中，选择`@timestamp`字段，然后点击 `Save data view to Kibana`。

创建完成后，点击左侧导航菜单中的 `Discover`，并在 Data views 区域选择上面创建的 `K8sLogs`，然后就可以看到一些直方图和最近采集到的日志数据了：

![1691051970372.jpg](./img/8A-0JCnD55QHvnmA/1693830586913-1e1f5358-c490-4c1a-b474-6c85cb9c57eb-147880.jpeg)

现在的数据就是上面 Counter 应用的日志，如果还有其他的应用，我们也可以筛选过滤：

![1691052205488.jpg](./img/8A-0JCnD55QHvnmA/1693830586883-d4e26a2b-973c-44f8-bd6f-af4895387e01-287679.jpeg)

我们也可以通过其他元数据来过滤日志数据，比如您可以单击任何日志条目以查看其他元数据，如容器名称，Kubernetes 节点，命名空间等。


## 安装 Kafka

对于大规模集群来说，日志数据量是非常巨大的，如果直接通过 Fluentd 将日志打入 Elasticsearch，对 ES 来说压力是非常巨大的，我们可以在中间加一层消息中间件来缓解 ES 的压力，一般情况下我们会使用 Kafka，然后可以直接使用 `kafka-connect-elasticsearch` 这样的工具将数据直接打入 ES，也可以在加一层 Logstash 去消费 Kafka 的数据，然后通过 Logstash 把数据存入 ES，这里我们来使用 Logstash 这种模式来对日志收集进行优化。

首先在 Kubernetes 集群中安装 Kafka，同样这里使用 Helm 进行安装：

```shell
$ helm repo add bitnami https://charts.bitnami.com/bitnami
$ helm repo update
```

首先使用 `helm pull` 拉取 Chart 并解压：

```shell
$ helm pull bitnami/kafka --untar --version 23.0.7
$ cd kafka
```

这里面我们指定使用一个 `StorageClass` 来提供持久化存储，在 Chart 目录下面创建用于安装的 values 文件：

```yaml
# values-kafka.yaml
## @section Persistence parameters
persistence:
  enabled: true
  storageClass: cfsauto # 指定使用的 StorageClass
  accessModes:
    - ReadWriteOnce
  size: 2Gi

  mountPath: /bitnami/kafka

# 默认使用 Kraft 模式，可以不使用Zookeeper，在这种模式下，Kafka节点可以作为控制器工作。
# 如果需要使用 Zookeeper 模式，需要将下面的 enabled 设置为 true
zookeeper:
  enabled: false
```

直接使用上面的 values 文件安装 kafka：

```shell
$ helm upgrade --install kafka -f values-kafka.yaml --namespace kube-log bitnami/kafka
Release "kafka" does not exist. Installing it now.
NAME: kafka
LAST DEPLOYED: Thu Aug  3 16:56:50 2023
NAMESPACE: kube-log
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: kafka
CHART VERSION: 23.0.7
APP VERSION: 3.5.1

** Please be patient while the chart is being deployed **

Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:

    kafka.kube-log.svc.cluster.local

Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:

    kafka-0.kafka-headless.kube-log.svc.cluster.local:9092

To create a pod that you can use as a Kafka client run the following commands:

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.5.1-debian-11-r1 --namespace kube-log --command -- sleep infinity
    kubectl exec --tty -i kafka-client --namespace kube-log -- bash

    PRODUCER:
        kafka-console-producer.sh \
            --broker-list kafka-0.kafka-headless.kube-log.svc.cluster.local:9092 \
            --topic test

    CONSUMER:
        kafka-console-consumer.sh \
            --bootstrap-server kafka.kube-log.svc.cluster.local:9092 \
            --topic test \
            --from-beginning
```

安装完成后我们可以使用上面的提示来检查 Kafka 是否正常运行：

```shell
$ kubectl get pods -n kube-log -l app.kubernetes.io/instance=kafka
kafka-0             1/1     Running   0          7m58s
kafka-zookeeper-0   1/1     Running   0          7m58s
```

用下面的命令创建一个 Kafka 的测试客户端 Pod：

```shell
$ kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.5.1-debian-11-r1 --namespace kube-log --command -- sleep infinity
pod/kafka-client created
```

然后启动一个终端进入容器内部生产消息：

```shell
# 生产者
$ kubectl exec --tty -i kafka-client --namespace kube-log -- bash
I have no name!@kafka-client:/$ kafka-console-producer.sh --broker-list kafka-0.kafka-headless.kube-log.svc.cluster.local:9092 --topic test
>hello kafka on k8s
>
```

启动另外一个终端进入容器内部消费消息：

```shell
# 消费者
$ kubectl exec --tty -i kafka-client --namespace kube-log -- bash
I have no name!@kafka-client:/$ kafka-console-consumer.sh --bootstrap-server kafka.kube-log.svc.cluster.local:9092 --topic test --from-beginning
hello kafka on k8s
```

如果在消费端看到了生产的消息数据证明我们的 Kafka 已经运行成功了。


## Fluentd 配置 Kafka

现在有了 Kafka，我们就可以将 Fluentd 的日志数据输出到 Kafka 了，只需要将 Fluentd 配置中的 `<match>` 更改为使用 Kafka 插件即可，但是在 Fluentd 中输出到 Kafka，需要使用到 `fluent-plugin-kafka` 插件，所以需要我们自定义下 Docker 镜像，最简单的做法就是在上面 Fluentd 镜像的基础上新增 kafka 插件即可，Dockerfile 文件如下所示：

```
FROM quay.io/fluentd_elasticsearch/fluentd:v4.4.3
RUN echo "source 'https://mirrors.tuna.tsinghua.edu.cn/rubygems/'" > Gemfile && gem install bundler
RUN gem install fluent-plugin-kafka -v 0.19.0 --no-document
```

使用上面的 `Dockerfile` 文件构建一个 Docker 镜像即可，我这里构建过后的镜像名为 `cnych/fluentd-kafka:v0.19.0`。接下来替换 Fluentd 的 Configmap 对象中的 `<match>` 部分，如下所示：

```yaml
# fluentd-config.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-conf
  namespace: logging
data:
  ......
  output.conf: |-
    <match **>
      @id kafka
      @type kafka2
      @log_level info

      # list of seed brokers
      brokers kafka-0.kafka-headless.kube-log.svc.cluster.local:9092
      use_event_time true

      # topic settings
      topic_key k8slog
      default_topic messages  # 注意，kafka中消费使用的是这个topic
      # buffer settings
      <buffer k8slog>
        @type file
        path /var/log/td-agent/buffer/td
        flush_interval 3s
      </buffer>

      # data type settings
      <format>
        @type json
      </format>

      # producer settings
      required_acks -1 # 0: async, 1: sync, -1: all
      compression_codec gzip  # snappy, gzip, lz4, or none

    </match>
```

然后替换运行的 Fluentd 镜像：

```yaml
# fluentd-ds.yaml
image: cnych/fluentd-kafka:v0.17.5
```

直接更新 Fluentd 的 Configmap 与 DaemonSet 资源对象即可：

```shell
$ kubectl apply -f fluentd-config.yaml
$ kubectl apply -f fluentd-ds.yaml
```

更新成功后我们可以使用上面的测试 Kafka 客户端来验证是否有日志数据：

```shell
$ kubectl exec --tty -i kafka-client --namespace kube-log -- bash
I have no name!@kafka-client:/$ kafka-console-consumer.sh --bootstrap-server kafka.kube-log.svc.cluster.local:9092 --topic messages --from-beginning
{"stream":"stdout","docker":{},"kubernetes":{"container_name":"count","namespace_name":"default","pod_name":"counter","container_image":"docker.io/library/busybox:latest","pod_ip":"10.244.2.97","host":"node2","labels":{"logging":"true"},"namespace_labels":{"kubernetes_io/metadata_name":"default"}},"message":"4774: Thu Aug  3 09:48:18 UTC 2023"}
......
```


## 安装 Logstash

虽然数据从 Kafka 到 Elasticsearch 的方式多种多样，比如可以使用 [Kafka Connect Elasticsearch Connector](https://github.com/confluentinc/kafka-connect-elasticsearch) 来实现，我们这里还是采用更加流行的 `Logstash` 方案，上面我们已经将日志从 Fluentd 采集输出到 Kafka 中去了，接下来我们使用 Logstash 来连接 Kafka 与 Elasticsearch 间的日志数据。

首先使用 `helm pull` 拉取 Chart 并解压：

```shell
$ helm pull elastic/logstash --untar --version 8.5.1
$ cd logstash
```

同样在 Chart 根目录下面创建用于安装的 Values 文件，如下所示：

```yaml
# values-logstash.yaml
fullnameOverride: logstash

logstashConfig:
  logstash.yml: |
    http.host: 0.0.0.0
    # 如果启用了xpack，需要做如下配置
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.hosts: ["http://demo-es-internal-http:9200"]
    xpack.monitoring.elasticsearch.username: "elastic"
    xpack.monitoring.elasticsearch.password: "$PASSWORD"

# 要注意下格式
logstashPipeline:
  logstash.conf: |
    input { kafka { bootstrap_servers => "kafka-0.kafka-headless.kube-log.svc.cluster.local:9092" codec => json consumer_threads => 3 topics => ["messages"] } }
    filter {}  # 过滤配置（比如可以删除key、添加geoip等等）
    output { elasticsearch { hosts => [ "demo-es-internal-http:9200" ] user => "elastic" password => "$PASSWORD" index => "logstash-k8s-%{+YYYY.MM.dd}" } stdout { codec => rubydebug } }
```

其中最重要的就是通过 `logstashPipeline` 配置 logstash 数据流的处理配置，通过 `input` 指定日志源 kafka 的配置，通过 `output` 输出到 Elasticsearch，同样直接使用上面的 Values 文件安装 logstash 即可：

```shell
$ helm upgrade --install logstash -f values-prod.yaml --namespace kube-log elastic/logstash
Release "logstash" does not exist. Installing it now.
NAME: logstash
LAST DEPLOYED: Thu Aug  3 17:17:06 2023
NAMESPACE: kube-log
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
1. Watch all cluster members come up.
  $ kubectl get pods --namespace=kube-log -l app=logstash -w
```

安装启动完成后可以查看 logstash 的日志：

```shell
$ kubectl get pods --namespace=kube-log -l app=logstash
NAME         READY   STATUS    RESTARTS   AGE
logstash-0   1/1     Running   0          2m8s
$ kubectl logs -f logstash-0 -n kube-log
......
{
    "kubernetes" => {
                  "labels" => {
            "logging" => "true"
        },
          "namespace_name" => "default",
                "pod_name" => "counter",
        "namespace_labels" => {
            "kubernetes_io/metadata_name" => "default"
        },
          "container_name" => "count",
                    "host" => "node2",
         "container_image" => "docker.io/library/busybox:latest",
                  "pod_ip" => "10.244.2.97"
    },
      "@version" => "1",
    "@timestamp" => 2023-08-03T10:33:43.772010644Z,
       "message" => "7494: Thu Aug  3 10:33:41 UTC 2023",
        "docker" => {},
        "stream" => "stdout",
         "event" => {
        "original" => "{\"stream\":\"stdout\",\"docker\":{},\"kubernetes\":{\"container_name\":\"count\",\"namespace_name\":\"default\",\"pod_name\":\"counter\",\"container_image\":\"docker.io/library/busybox:latest\",\"pod_ip\":\"10.244.2.97\",\"host\":\"node2\",\"labels\":{\"logging\":\"true\"},\"namespace_labels\":{\"kubernetes_io/metadata_name\":\"default\"}},\"message\":\"7494: Thu Aug  3 10:33:41 UTC 2023\"}"
    }
}
```

由于我们启用了 debug 日志调试，所以我们可以在 logstash 的日志中看到我们采集的日志消息，到这里证明我们的日志数据就获取成功了。

现在我们可以登录到 Kibana 可以看到有如下所示的索引数据了：

![1691058891857.png](./img/8A-0JCnD55QHvnmA/1693830587027-0363e5e2-b513-4eb9-901e-d9ca8b219e02-143120.png)

然后同样创建 Data View，匹配上面的索引即可：

![1691059003379.jpg](./img/8A-0JCnD55QHvnmA/1693830587085-c693cbcb-4c62-4c8a-bfd4-efb0782bd292-547587.jpeg)

创建完成后就可以前往发现页面过滤日志数据了：

![1691059111325.jpg](./img/8A-0JCnD55QHvnmA/1693830587125-b74d92d2-47a2-45c8-98e2-78eca4c16e9b-764040.jpeg)

到这里我们就实现了一个使用 `Fluentd + Kafka + Logstash + Elasticsearch + Kibana` 的 Kubernetes 日志收集工具栈，这里我们完整的 Pod 信息如下所示：

```shell
$ kubectl get pods -n kube-log
NAME                       READY   STATUS    RESTARTS   AGE
demo-es-default-0          1/1     Running   0          46h
demo-kb-7bcf498c4b-tf5t4   1/1     Running   0          46h
fluentd-btpvf              1/1     Running   0          56m
fluentd-h7t2f              1/1     Running   0          57m
fluentd-lnp4d              1/1     Running   0          54m
kafka-0                    1/1     Running   0          102m
kafka-client               1/1     Running   0          95m
logstash-0                 1/1     Running   0          81m
```

当然在实际的工作项目中还需要我们根据实际的业务场景来进行参数性能调优以及高可用等设置，以达到系统的最优性能。

上面我们在配置 `logstash` 的时候是将日志输出到 `"logstash-k8s-%{+YYYY.MM.dd}"` 这个索引模式的，可能有的场景下只通过日期去区分索引不是很合理，那么我们可以根据自己的需求去修改索引名称，比如可以根据我们的服务名称来进行区分，那么这个服务名称可以怎么来定义呢？可以是 Pod 的名称或者通过 label 标签去指定，比如我们这里去做一个规范，要求需要收集日志的 Pod 除了需要添加 `logging: true` 这个标签之外，还需要添加一个 `logIndex: <索引名>` 的标签。

比如重新更新我们测试的 counter 应用：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
  labels:
    logging: "true" # 一定要具有该标签才会被采集
    logIndex: "test" # 指定索引名称
spec:
  containers:
    - name: count
      image: busybox
      args:
        [
          /bin/sh,
          -c,
          'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done',
        ]
```

然后重新更新 logstash 的配置，修改 values 配置：

```yaml
# ......
logstashPipeline:
  logstash.conf: |
    input { kafka { bootstrap_servers => "kafka-0.kafka-headless.kube-log.svc.cluster.local:9092" codec => json consumer_threads => 3 topics => ["messages"] } }
    filter {}  # 过滤配置（比如可以删除key、添加geoip等等）
    output { elasticsearch { hosts => [ "elasticsearch-client:9200" ] user => "elastic" password => "$PASSWORD" index => "k8s-%{[kubernetes][labels][logIndex]}-%{+YYYY.MM.dd}" } stdout { codec => rubydebug } }

# ......
```

使用上面的 values 值更新 logstash，正常更新后上面的 counter 这个 Pod 日志会输出到一个名为 `k8s-test-2022.06.09` 的索引去。

![1691059951360.png](./img/8A-0JCnD55QHvnmA/1693830587075-fbb3ef81-aa9f-4231-9f8b-b175f0cde589-868039.png)

这样我们就实现了自定义索引名称，当然你也可以使用 Pod 名称、容器名称、命名空间名称来作为索引的名称，这完全取决于你自己的需求。


> 原文: <https://www.yuque.com/cnych/k8s4/engq739mdeeczawe>